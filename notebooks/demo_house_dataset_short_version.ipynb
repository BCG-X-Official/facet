{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "**This notebook serves as a demo and tutorial for the yielengine package.**\n",
    "It illustrates the following methods:\n",
    "- Usage of the yieldengine API that wrap sklearn functionalities so that transformes output dataframe with meaningfull column names\n",
    "- EDA\n",
    "- Boruta feature selection\n",
    "- Shap clustering feature selection\n",
    "- Simulaiton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible datasets:\n",
    "- https://archive.ics.uci.edu/ml/datasets/Concrete+Compressive+Strength concrete strength (9 variables)\n",
    "- https://archive.ics.uci.edu/ml/datasets/Energy+efficiency energetical performance (8 variables)\n",
    "- https://archive.ics.uci.edu/ml/datasets/Insurance+Company+Benchmark+%28COIL+2000%29 : regression problem: know if a client subscribes for an insurance\n",
    "- https://archive.ics.uci.edu/ml/datasets/Online+News+Popularity Popularity of an article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T17:51:01.626003Z",
     "start_time": "2019-07-19T17:51:01.615001Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print the used verion of Python to be sure that you are using the yield-engine environement\n",
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T17:51:01.643004Z",
     "start_time": "2019-07-19T17:51:01.629008Z"
    }
   },
   "outputs": [],
   "source": [
    "PATH_YIELD_ENGINE = 'src'\n",
    "\n",
    "def set_paths() -> None:\n",
    "    \"\"\"\n",
    "    set correct working directory and python path when started from within PyCharm\n",
    "    \"\"\"\n",
    "    import sys\n",
    "    import os\n",
    "    \n",
    "    if 'cwd' not in globals():\n",
    "        # noinspection PyGlobalUndefined\n",
    "        global cwd\n",
    "        cwd = os.path.join(os.getcwd(), os.pardir)\n",
    "        os.chdir(cwd)\n",
    "    \n",
    "    print(f\"working dir is '{os.getcwd()}'\")\n",
    "                             \n",
    "    if PATH_YIELD_ENGINE not in sys.path:\n",
    "        sys.path.insert(0, PATH_YIELD_ENGINE)\n",
    "    \n",
    "    print(f\"added `{sys.path[0]}` to python paths\")\n",
    "\n",
    "set_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T17:51:05.194169Z",
     "start_time": "2019-07-19T17:51:01.646003Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os    \n",
    "import re\n",
    "import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import make_scorer, r2_score, mean_absolute_error\n",
    "from typing import *\n",
    "\n",
    "from yieldengine import Sample\n",
    "from yieldengine.dendrogram import DendrogramDrawer\n",
    "from yieldengine.dendrogram.style import FeatMapStyle, LineStyle\n",
    "from yieldengine.df.pipeline import PipelineDF\n",
    "from yieldengine.preprocessing.encode import OneHotEncoderDF\n",
    "from yieldengine.preprocessing.impute import SimpleImputerDF, MissingIndicatorDF\n",
    "from yieldengine.preprocessing.selection import BorutaDF\n",
    "from yieldengine.preprocessing.compose import ColumnTransformerDF\n",
    "from yieldengine.model.inspection import ModelInspector\n",
    "from yieldengine.model.prediction import PredictorFitCV\n",
    "from yieldengine.model.selection import ModelPipelineDF, ModelGrid, ModelRanker, summary_report, ModelEvaluation, ModelScoring\n",
    "from yieldengine.model.validation import CircularCrossValidator\n",
    "from yieldengine.visualization.eda import plot_ecdf, plot_ecdf_df, plot_hist_df\n",
    "from yieldengine.preprocessing.outlier import OutlierRemoverDF\n",
    "from yieldengine.preprocessing import FunctionTransformerDF\n",
    "from yieldengine.simulation import UnivariateSimulator\n",
    "from yieldengine.partition import ContinuousRangePartitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T17:51:05.201050Z",
     "start_time": "2019-07-19T17:51:05.196050Z"
    }
   },
   "outputs": [],
   "source": [
    "# Enlarge the width of the cells\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T17:51:05.221053Z",
     "start_time": "2019-07-19T17:51:05.203054Z"
    }
   },
   "outputs": [],
   "source": [
    "# Only show matplolib warning logging messages, otherwise there are too many\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)\n",
    "log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T17:51:05.238053Z",
     "start_time": "2019-07-19T17:51:05.223055Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [8, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T17:51:05.245051Z",
     "start_time": "2019-07-19T17:51:05.241050Z"
    }
   },
   "outputs": [],
   "source": [
    "IQR_MULTIPLE = 1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load raw data, EDA and data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T17:51:05.295053Z",
     "start_time": "2019-07-19T17:51:05.248054Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join('data', 'ames-housing-dataset')\n",
    "RAW_DATA_CSV = os.path.join(DATA_DIR, 'train.csv')\n",
    "TARGET = \"SalePrice\"\n",
    "\n",
    "print(f\"Read {RAW_DATA_CSV}\")\n",
    "raw_df = pd.read_csv(RAW_DATA_CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T17:51:05.330055Z",
     "start_time": "2019-07-19T17:51:05.297052Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Shape of the raw data: {raw_df.shape}\")\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T17:51:05.340069Z",
     "start_time": "2019-07-19T17:51:05.332068Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T17:51:05.354050Z",
     "start_time": "2019-07-19T17:51:05.343079Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_df = raw_df.copy()\n",
    "# Drop the Id column and date columns\n",
    "dataset_df = dataset_df.drop(['Id', 'YrSold', 'MoSold'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T17:51:05.391057Z",
     "start_time": "2019-07-19T17:51:05.356050Z"
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# remove infinity values\n",
    "dataset_df = dataset_df.replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T17:51:05.566054Z",
     "start_time": "2019-07-19T17:51:05.393052Z"
    }
   },
   "outputs": [],
   "source": [
    "features_df = dataset_df.drop(columns=TARGET)\n",
    "cat_features = features_df.select_dtypes(['category', object]).columns\n",
    "num_features = features_df.select_dtypes('number').columns\n",
    "print (f\"{features_df.shape[1] - len(cat_features) - len(num_features)} not a number or category\")\n",
    "del features_df\n",
    "\n",
    "for col_name in cat_features:\n",
    "    dataset_df.loc[:, col_name] = (\n",
    "        dataset_df.loc[:, col_name].astype(object).fillna('missing value').astype(str).str.strip().str.lower().astype('category')\n",
    "    )\n",
    "# output datasets\n",
    "dt = dataset_df.dtypes.rename('dtype').astype(str)\n",
    "dt.groupby(by=dt.values).count().to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity we select only numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T17:51:05.573056Z",
     "start_time": "2019-07-19T17:51:05.567054Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_df = dataset_df[list(num_features) + [TARGET]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T15:37:32.105528Z",
     "start_time": "2019-06-19T15:37:32.089954Z"
    }
   },
   "source": [
    "## Remove outliers\n",
    "We remove the samples whose target value is an outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T17:51:05.586055Z",
     "start_time": "2019-07-19T17:51:05.575055Z"
    }
   },
   "outputs": [],
   "source": [
    "outlier_remover = OutlierRemoverDF(iqr_multiple=IQR_MULTIPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T17:51:05.623057Z",
     "start_time": "2019-07-19T17:51:05.588053Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filter out the rows of the dataset where the target is  an outlier\n",
    "print(f\"Shape before removal of target outlier: {dataset_df.shape}\")\n",
    "mask = outlier_remover.fit_transform(dataset_df[[TARGET]])[TARGET].notna()\n",
    "dataset_df = dataset_df.loc[mask, :]\n",
    "print(f\"Shape after removal of target outlier: {dataset_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Sample object to be used by our model\n",
    "The **Sample** class is a wrapper around a dataframe, which also specifies which columns are features and which column is the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T17:51:05.631056Z",
     "start_time": "2019-07-19T17:51:05.626068Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a Sample object to be used by our model\n",
    "sample_full = Sample(\n",
    "    observations=dataset_df,\n",
    "    target_name=TARGET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plot of the empirical cumulative distribution function (ECDF) of the target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T17:51:05.820058Z",
     "start_time": "2019-07-19T17:51:05.633056Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_ecdf(sample_full.target, iqr_multiple=IQR_MULTIPLE, iqr_multiple_far=IQR_MULTIPLE*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boruta feature selection\n",
    "In a nutshell, the Boruta algorithm discards the features which are not more predictive than random noise. \n",
    "See https://www.datacamp.com/community/tutorials/feature-selection-R-boruta  for more explanations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imputation and encoding\n",
    "We first define a Pipeline that will be used before running Boruta. All the transformers are wrapper around scikit-learn transformers which return a Dataframe with the appropriate column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T17:51:05.830062Z",
     "start_time": "2019-07-19T17:51:05.822059Z"
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def make_preprocessor(sample: Sample, onehot: bool = True, missing: bool = True) -> ColumnTransformerDF:\n",
    "    tx = []\n",
    "    # define how features should be preprocessed\n",
    "    tx.append((\"impute\", \n",
    "               SimpleImputerDF(strategy=\"median\"), \n",
    "               sample.features_by_type(Sample.DTYPE_NUMERICAL).columns))\n",
    "\n",
    "    if missing:\n",
    "        tx.append((\"missing\", \n",
    "                   MissingIndicatorDF(error_on_new=False), \n",
    "                   sample.features_by_type(Sample.DTYPE_NUMERICAL).columns))\n",
    "        \n",
    "    if onehot:\n",
    "        tx.append((\"onehot\", \n",
    "                   OneHotEncoderDF(sparse=False, handle_unknown=\"ignore\"),\n",
    "                   sample.features_by_type([Sample.DTYPE_CATEGORICAL]).columns))     \n",
    "\n",
    "    return ColumnTransformerDF(transformers=tx)\n",
    "\n",
    "def make_outlier_transformer(sample: Sample, iqr_threshold) -> ColumnTransformerDF:    \n",
    "    outlier_transformers = [\n",
    "        ('outlier', OutlierRemoverDF(iqr_multiple=IQR_MULTIPLE), sample_full.features_by_type(Sample.DTYPE_NUMERICAL).columns),\n",
    "        ('rest', FunctionTransformerDF(validate=False), sample_full.features_by_type(Sample.DTYPE_OBJECT).columns)\n",
    "    ]\n",
    "    outlier_step = ColumnTransformerDF(transformers=outlier_transformers)\n",
    "    return outlier_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T17:51:05.878060Z",
     "start_time": "2019-07-19T17:51:05.832062Z"
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "preprocessor = make_preprocessor(sample=sample_full, missing=True, onehot=True)\n",
    "outlier_step = make_outlier_transformer(sample=sample_full, iqr_threshold=IQR_MULTIPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection (Boruta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T17:51:05.886073Z",
     "start_time": "2019-07-19T17:51:05.880066Z"
    }
   },
   "outputs": [],
   "source": [
    "boruta_selector = PipelineDF(\n",
    "    steps = [\n",
    "        ('outlier_removal', outlier_step),\n",
    "        ('preprocess', preprocessor),\n",
    "        ('boruta', BorutaDF(estimator=RandomForestRegressor(max_depth=5,min_samples_leaf=8,\n",
    "                                                            random_state=42,n_jobs=-3),\n",
    "                             n_estimators=10, verbose=2, max_iter=10, random_state=42))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T17:51:08.165252Z",
     "start_time": "2019-07-19T17:51:05.891073Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boruta_selector.fit(sample_full.features, sample_full.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T17:51:08.197293Z",
     "start_time": "2019-07-19T17:51:08.167334Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features_removed_by_boruta = set(boruta_selector.columns_in) - set(boruta_selector.columns_original)\n",
    "print(f\"Boruta remove {len(features_removed_by_boruta)} features:\\n{features_removed_by_boruta}\")\n",
    "selected = sorted(list(set(boruta_selector.columns_original)))\n",
    "print(\"\\nList of the features selected by Boruta:\")\n",
    "pprint.pprint(list(selected))\n",
    "if selected is None:\n",
    "    raise Error(\"You need to specify a backup set of variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T17:51:08.206262Z",
     "start_time": "2019-07-19T17:51:08.199254Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = sample_full.select_features(selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization of numerical features and categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T17:51:09.758708Z",
     "start_time": "2019-07-19T17:51:08.210260Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_ecdf_df(sample.features, iqr_multiple=IQR_MULTIPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ModelPipelineDF training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search and cross validator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a custom CV splitter defined in the yield-engine package (see https://scikit-learn.org/stable/glossary.html#term-cv-splitter for the scikit-learn API regarding CV splitter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T17:51:09.764663Z",
     "start_time": "2019-07-19T17:51:09.760665Z"
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# define the circular cross validator with 30 folds\n",
    "circular_cv = CircularCrossValidator(test_ratio=1/3, num_splits=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class **ModelPipelineDF** specifies a model as an estimator and a preprocessing pipeline.\n",
    "The class **ModelGrid** specifies a **ModelPipelineDF**  and a hyperparameter grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T17:51:09.793708Z",
     "start_time": "2019-07-19T17:51:09.766665Z"
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_model_grids(sample: Sample) -> List[ModelGrid]:\n",
    "    grids = [ModelGrid(\n",
    "         model=ModelPipelineDF(predictor=RandomForestRegressor(random_state=42),\n",
    "                     preprocessing=make_preprocessor(sample=sample, missing=False)),\n",
    "         estimator_parameters = {\"n_estimators\": [10],\n",
    "                                 \"max_depth\": [4,5,6],\n",
    "                                 \"min_samples_leaf\": [4],\n",
    "                                 \"criterion\": [\"mse\"], #[\"mae\",\"mse\"],\n",
    "                                 \"max_features\": [1.0]})]\n",
    "    return grids\n",
    "grids = get_model_grids(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T17:51:14.409728Z",
     "start_time": "2019-07-19T17:51:09.794707Z"
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ranker = ModelRanker(grids=grids, cv=circular_cv)\n",
    "ranking = ranker.run(sample, n_jobs=-3)\n",
    "print(summary_report(ranking))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T17:51:14.419769Z",
     "start_time": "2019-07-19T17:51:14.411731Z"
    }
   },
   "outputs": [],
   "source": [
    "top_model = ranking[0]\n",
    "print(top_model.scoring['test_score'])\n",
    "print(top_model.parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ModelPipelineDF inspection\n",
    "The **PredictorFitCV** summarizes all the information of a model: the estimator used for the model, the CV (=cross-validation) type, and the **Sample** itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T17:51:14.558776Z",
     "start_time": "2019-07-19T17:51:14.421727Z"
    }
   },
   "outputs": [],
   "source": [
    "predictor = PredictorFitCV(model=top_model.model, cv=circular_cv, sample=sample)\n",
    "inspector = ModelInspector(predictor)\n",
    "predictions = predictor.predictions_for_all_splits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T17:51:14.782730Z",
     "start_time": "2019-07-19T17:51:14.560771Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(sample.target.sort_index(), \n",
    "            predictions.groupby(predictions.index)['prediction'].mean().sort_index(), alpha=.3)\n",
    "plt.xlabel('actual')\n",
    "plt.ylabel('predicted');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inspector object allows directly to acces the shap values of the model. These shap values are computed for a given sample as the average of the shap values over all the test folds containg that given sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T17:51:14.933732Z",
     "start_time": "2019-07-19T17:51:14.783730Z"
    }
   },
   "outputs": [],
   "source": [
    "M = inspector.shap_matrix()\n",
    "M.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T17:51:14.945734Z",
     "start_time": "2019-07-19T17:51:14.934780Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inspector.feature_importances().sort_values(ascending=False).to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shap clustering\n",
    "The Shap clustering clusters the features using as distance between the features, the correlation matrix of the shap values.\n",
    "Then using a hierarchical clustering, and visualization style defined in the yield-engine package, one can easily visualize the clustering of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T17:51:14.969773Z",
     "start_time": "2019-07-19T17:51:14.947733Z"
    }
   },
   "outputs": [],
   "source": [
    "linkage_tree = inspector.cluster_dependent_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T17:51:15.359739Z",
     "start_time": "2019-07-19T17:51:14.971735Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "number_features = predictor.sample.features.shape[1]\n",
    "ax = plt.figure(figsize=(10,number_features*0.5)).add_subplot(111)\n",
    "style = LineStyle(ax)\n",
    "DendrogramDrawer(title=TARGET, linkage_tree=linkage_tree, style=style).draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T17:51:15.790745Z",
     "start_time": "2019-07-19T17:51:15.362740Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "number_features = predictor.sample.features.shape[1]\n",
    "ax = plt.figure(figsize=(10, number_features*.5)).add_subplot(111)\n",
    "style = FeatMapStyle(ax)\n",
    "DendrogramDrawer(title=TARGET, linkage_tree=linkage_tree, style=style).draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is desirable to have a model with\n",
    "- good predictivity (good R2 score for instance)\n",
    "- few features\n",
    "- independent features  \n",
    "\n",
    "With the above dendrograms one can isolate **features with low importance and which are strongly realted to other features. It makes sense to discard those.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shap clustering iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method the run an iteration\n",
    "Based on the above remarks, who are going to run a clustering iteration as:\n",
    "1. Based on the shap dendrogram select features to discard\n",
    "2. Re-run the model with the new set of features\n",
    "3. Plot again the shap dendrogram to see if the feautures are more independent, and iterate this process if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T17:51:15.800748Z",
     "start_time": "2019-07-19T17:51:15.792789Z"
    }
   },
   "outputs": [],
   "source": [
    "def shap_clustering_iteration(sample: Sample, black_list: List[str]) -> Tuple[Sample, ModelInspector]:\n",
    "    \"\"\"Removing black list features, and retrain the model. Return a new sample and a fitted model inspector.\"\"\"\n",
    "    # Create a new Sample by removing the features in the blacklist\n",
    "    features = sample.feature_names\n",
    "    if not set(black_list) <= set(features):\n",
    "        log.warning(f\"\"\"The black list must be a subset of the set of features: the features \n",
    "        {set(black_list)-set(features)} are in black list but not in the features.\"\"\")\n",
    "\n",
    "    white_list = sorted(list(set(features) - set(black_list)))\n",
    "    log.info(f\"New white list:\\n {white_list}\")\n",
    "    new_sample = sample.select_features(white_list)\n",
    "    \n",
    "    # Create the preprocessing pipeline for the model run\n",
    "    outlier_step = make_outlier_transformer(sample=new_sample, iqr_threshold=IQR_MULTIPLE)\n",
    "    preprocessor = make_preprocessor(sample=new_sample, missing=True, onehot=True)\n",
    "    pipeline = PipelineDF(steps = [('outlier_removal', outlier_step), ('preprocess', preprocessor)])\n",
    "    \n",
    "    # Run the pipeline\n",
    "    grids = get_model_grids(new_sample)\n",
    "    ranker = ModelRanker(grids=grids, cv=circular_cv)\n",
    "    ranking = ranker.run(new_sample, n_jobs=-3)\n",
    "    top_model = ranking[0]\n",
    "    \n",
    "    # Report the model result\n",
    "    print(summary_report(ranking))\n",
    "    print(f\"top_model score: {top_model.scoring['test_score']}\")\n",
    "    print(f\"top_model parameters: {top_model.parameters}\")\n",
    "    predictor = PredictorFitCV(model=top_model.model, cv=circular_cv, sample=new_sample)\n",
    "    inspector = ModelInspector(predictor)\n",
    "    \n",
    "    return new_sample, inspector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T17:51:15.815750Z",
     "start_time": "2019-07-19T17:51:15.803745Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_shap_dendrogram(inspector: ModelInspector) -> None:\n",
    "    \"\"\"Plot dendrogram of the shape clustering.\"\"\"\n",
    "    M = inspector.shap_matrix()\n",
    "    number_features = inspector.model_fit.sample.features.shape[1]\n",
    "    linkage_tree = inspector.cluster_dependent_features()\n",
    "    ax = plt.figure(figsize=(10,number_features*.5)).add_subplot(111)\n",
    "    style = FeatMapStyle(ax)\n",
    "    DendrogramDrawer(title=TARGET, linkage_tree=linkage_tree, style=style).draw();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shap culstering iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T17:51:15.828757Z",
     "start_time": "2019-07-19T17:51:15.817750Z"
    }
   },
   "outputs": [],
   "source": [
    "black_list1 = ['WoodDeckSF', \n",
    "               #'BsmtFinSF1', \n",
    "               \"OpenPorchSF\",\n",
    "               #\"MSSubClass\",\n",
    "               \"KitchenAbvGr\",\n",
    "               'BsmtUnfSF', \n",
    "               #'MasVnrArea',\n",
    "               'LotFrontage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T17:51:16.040748Z",
     "start_time": "2019-07-19T17:51:15.830747Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample1, inspector1 = shap_clustering_iteration(sample, black_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T17:51:16.687802Z",
     "start_time": "2019-07-19T17:51:16.042751Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_shap_dendrogram(inspector1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shap clustering iteration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T17:51:16.693761Z",
     "start_time": "2019-07-19T17:51:16.690760Z"
    }
   },
   "outputs": [],
   "source": [
    "black_list2 = [\n",
    "    \"YearRemodAdd\",\n",
    "    \"OverallCond\",\n",
    "    \"2ndFlrSF\",\n",
    "    #\"MSSubClass\",\n",
    "    #\"KitchenAbvGr\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T17:51:16.849800Z",
     "start_time": "2019-07-19T17:51:16.695757Z"
    }
   },
   "outputs": [],
   "source": [
    "sample2, inspector2 = shap_clustering_iteration(sample1, black_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T17:51:17.460812Z",
     "start_time": "2019-07-19T17:51:16.851765Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_shap_dendrogram(inspector2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation\n",
    "The simulation builds partial dependency plots which allow to assess the impact thta the value of a given feature has on the model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T17:51:17.464772Z",
     "start_time": "2019-07-19T17:51:17.461782Z"
    }
   },
   "outputs": [],
   "source": [
    "model_fit = inspector2.model_fit\n",
    "sim = UnivariateSimulator(model_fit=model_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T17:51:17.508766Z",
     "start_time": "2019-07-19T17:51:17.466836Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "dd = widgets.Dropdown(\n",
    "    options=predictor.sample.features.columns,\n",
    "    description='Feature:',\n",
    "    disabled=False,\n",
    "    layout={\"width\":\"550px\"}\n",
    ")\n",
    "\n",
    "btn = widgets.Button(description='Simulate')\n",
    "\n",
    "def plot_simulation(feature:str):\n",
    "    feature_values = ContinuousRangePartitioning(dataset_df.loc[:,feature]).partitions()\n",
    "    yield_change = sim.simulate_feature(\n",
    "            feature_name=feature,\n",
    "            feature_values=feature_values,\n",
    "    )\n",
    "    \n",
    "    yield_change_aggr = UnivariateSimulator.aggregate_simulation_results(\n",
    "                    results_per_split=yield_change, percentiles=[10, 50, 90])\n",
    "    \n",
    "    XLABEL_TITLE = f\"{feature}\"\n",
    "    YLABEL_TITLE = f\"Predicted mean yield uplift ({TARGET})\"\n",
    "    COLOR1 = 'red'\n",
    "    COLOR2 = 'silver'\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(nrows=2, figsize=(10,10), sharex=True)\n",
    "    \n",
    "    # plot lines of prediction\n",
    "    ax1.set_xlabel(XLABEL_TITLE, color='black', labelpad=10, fontsize=12)\n",
    "    ax1.set_ylabel(YLABEL_TITLE, color='black', fontsize=12)\n",
    "    line1, = ax1.plot(yield_change_aggr.index, yield_change_aggr.iloc[:,0], color=COLOR2, linewidth=1)\n",
    "    line2, = ax1.plot(yield_change_aggr.index, yield_change_aggr.iloc[:,1], color=COLOR1)\n",
    "    line3, = ax1.plot(yield_change_aggr.index, yield_change_aggr.iloc[:,2], color=COLOR2, linewidth=1)\n",
    "    ax1.axhline(y=0, color='black', linewidth=.5)\n",
    "    ax1.tick_params(axis='x', labelcolor='black')\n",
    "    for pos in ['top', 'right', 'bottom']:\n",
    "        ax1.spines[pos].set_visible(False)\n",
    "    ax1.tick_params(axis='x', labelbottom=True, bottom=False)\n",
    "    ax1.legend((line3, line2, line1), ('90th percentile', 'Median', '10th percentile'), frameon=False)\n",
    "    \n",
    "    # plot the histogram\n",
    "    x = sample.features[feature].dropna()\n",
    "    hist_range = (min(yield_change_aggr.index), max(yield_change_aggr.index))\n",
    "    n, bins, patches = ax2.hist(x, edgecolor='white', color=COLOR2, range=hist_range)\n",
    "    bins1 = pd.Series(bins).rolling(window=2).mean().shift(-1).dropna()\n",
    "    ax2.invert_yaxis()\n",
    "    ax2.tick_params(axis='y', labelcolor='black')\n",
    "    max_y = max(n)\n",
    "    y_offset = max_y * 0.05\n",
    "    for (x,y) in zip(bins1, n):\n",
    "        if y>0:\n",
    "            ax2.text(x, y + y_offset, str(int(y)), color='black', horizontalalignment='center')\n",
    "    ax2.get_yaxis().set_visible(False)\n",
    "    ax2.get_xaxis().set_visible(False)\n",
    "    for pos in ['top', 'right', 'left', 'bottom']:\n",
    "        ax2.spines[pos].set_visible(False)\n",
    "    plt.subplots_adjust(hspace=.2)\n",
    "    plt.show()\n",
    "\n",
    "def on_click(btn):\n",
    "    clear_output()\n",
    "    display(widgets.HBox([dd, btn]))\n",
    "    plot_simulation(feature=dd.value)\n",
    "    \n",
    "btn.on_click(on_click)    \n",
    "display(widgets.HBox([dd, btn]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "688px",
    "left": "97px",
    "top": "110.233px",
    "width": "229.6px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
