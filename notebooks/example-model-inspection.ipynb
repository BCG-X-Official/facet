{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Front matter\n",
    "\n",
    "_Important_: On first run, set CACHING to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "CACHING = False\n",
    "EXPERIMENTAL = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Set path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "PATH_YIELD_ENGINE = 'src'\n",
    "\n",
    "def set_paths() -> None:\n",
    "    \"\"\"\n",
    "    set correct working directory and python path when started from within PyCharm\n",
    "    \"\"\"\n",
    "    import sys\n",
    "    import os\n",
    "    \n",
    "    if 'cwd' not in globals():\n",
    "        # noinspection PyGlobalUndefined\n",
    "        global cwd\n",
    "        cwd = os.path.join(os.getcwd(), os.pardir)\n",
    "        os.chdir(cwd)\n",
    "    \n",
    "    print(f\"working dir is '{os.getcwd()}'\")\n",
    "                             \n",
    "    if PATH_YIELD_ENGINE not in sys.path:\n",
    "        sys.path.insert(0, PATH_YIELD_ENGINE)\n",
    "    \n",
    "    print(f\"added `{sys.path[0]}` to python paths\")\n",
    "\n",
    "set_paths()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%  \n"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm.sklearn import LGBMRegressor\n",
    "from matplotlib import cm\n",
    "from matplotlib.pyplot import figure\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import tests\n",
    "from tests.model import make_simple_transformer\n",
    "from tests.paths import TEST_DATA_CSV\n",
    "from yieldengine import Sample\n",
    "from yieldengine.dendrogram import DendrogramDrawer\n",
    "from yieldengine.dendrogram.style import DendrogramHeatmapStyle, DendrogramLineStyle\n",
    "from yieldengine.preprocessing.impute import SimpleImputerDF\n",
    "from yieldengine.preprocessing.selection import BorutaDF\n",
    "from yieldengine.model.inspection import ModelInspector\n",
    "from yieldengine.model.prediction import ModelFitCV\n",
    "from yieldengine.df.pipeline import PipelineDF\n",
    "from yieldengine.model.selection import ModelPipelineDF, ModelGrid, BaseLearnerRanker\n",
    "from yieldengine.model.validation import CircularCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "PATH_TMP = 'tmp'\n",
    "MI_PKL = os.path.join(PATH_TMP, 'model_inspector.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "inputfile_config = tests.read_test_config(section=\"inputfile\")\n",
    "\n",
    "batch_df = pd.read_csv(\n",
    "    filepath_or_buffer=TEST_DATA_CSV,\n",
    "    delimiter=inputfile_config[\"delimiter\"],\n",
    "    header=inputfile_config[\"header\"],\n",
    "    decimal=inputfile_config[\"decimal\"],\n",
    ")\n",
    "\n",
    "batch_df = batch_df.drop(columns=[\"Date\", \"Batch Id\"])\n",
    "\n",
    "# replace values of +/- infinite with n/a, then drop all n/a columns:\n",
    "batch_df = batch_df.replace([np.inf, -np.inf], np.nan).dropna(\n",
    "    axis=1, how=\"all\"\n",
    ")\n",
    "batch_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# define a Sample based on the test batch_file\n",
    "sample = Sample(observations=batch_df, target=\"Yield\")\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# define the circular cross validator with 10 folds\n",
    "circular_cv = CircularCV(test_ratio=0.2, num_splits=10)\n",
    "\n",
    "circular_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CACHING:\n",
    "    boruta_selector = PipelineDF(steps=[\n",
    "        (\n",
    "            'preprocess', \n",
    "            make_simple_transformer(\n",
    "                impute_median_columns=sample.features_by_type(Sample.DTYPE_NUMERICAL).columns,\n",
    "                one_hot_encode_columns=sample.features_by_type(Sample.DTYPE_OBJECT).columns,\n",
    "            )\n",
    "        ),\n",
    "        (\n",
    "            'boruta', \n",
    "            BorutaDF(\n",
    "                estimator=RandomForestRegressor(n_jobs=4),\n",
    "                max_iter=100,\n",
    "                n_estimators='auto', \n",
    "                verbose=2, \n",
    "                random_state=42\n",
    "            )\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    feature_selection = boruta_selector.fit_transform(\n",
    "            sample.features, \n",
    "            sample.target\n",
    "        )\n",
    "    \n",
    "    selected_features = boruta_selector.features_original\n",
    "\n",
    "    sample_post_boruta = sample.select_features(selected_features)\n",
    "    \n",
    "    selected_features.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# define a transformer step based on the sample\n",
    "if not CACHING:\n",
    "    preprocessor = make_simple_transformer(\n",
    "            impute_median_columns=sample_post_boruta.features_by_type(Sample.DTYPE_NUMERICAL).columns,\n",
    "            one_hot_encode_columns=sample_post_boruta.features_by_type(Sample.DTYPE_OBJECT).columns,\n",
    "    )\n",
    "    preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "if not CACHING:\n",
    "    # define a ModelPipelineDF with a preprocessing pipeline\n",
    "    lgbm = ModelGrid(\n",
    "                model=ModelPipelineDF(\n",
    "                    preprocessing=preprocessor, estimator=LGBMRegressor()\n",
    "                ),\n",
    "                learner_parameters={\n",
    "                    \"max_depth\": [5, 10],\n",
    "                    \"min_split_gain\": [0.1, 0.2],\n",
    "                    \"num_leaves\": [50, 100, 200],\n",
    "                    \"random_state\": [42],\n",
    "                },\n",
    "    )\n",
    "    lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "if not CACHING:\n",
    "    # define a BaseLearnerRanker\n",
    "    model_ranker: BaseLearnerRanker = BaseLearnerRanker(\n",
    "            grids=[lgbm], cv=circular_cv, scoring=\"r2\"\n",
    "        )\n",
    "\n",
    "    # run the BaseLearnerRanker to retrieve a ranking\n",
    "    model_ranking = model_ranker.run(sample=sample_post_boruta)\n",
    "    # noinspection PyStatementEffect\n",
    "else:\n",
    "    model_ranking = None\n",
    "    \n",
    "model_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "if not CACHING:\n",
    "    # retrieve the best model\n",
    "    best_model = model_ranking[0]\n",
    "    # noinspection PyStatementEffect\n",
    "    best_model\n",
    "else:\n",
    "    best_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "if not CACHING:\n",
    "    # defina a Predictor CV\n",
    "    mf = ModelFitCV(\n",
    "        model=best_model.model,\n",
    "        cv=circular_cv,\n",
    "        sample=sample\n",
    "    )\n",
    "    # define a ModelInspector\n",
    "    mi = ModelInspector(model_fit=mf)\n",
    "\n",
    "    mi.feature_dependency_matrix()\n",
    "\n",
    "    with open(MI_PKL, 'wb') as f:\n",
    "        pickle.dump(mi, f)\n",
    "else:\n",
    "    with open(MI_PKL, 'rb') as f:\n",
    "        mi = pickle.load(f)\n",
    "\n",
    "mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# retrieve a the shap_values\n",
    "mi.shap_values().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "mi.feature_dependency_matrix().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if EXPERIMENTAL:\n",
    "    mi.plot_feature_dendrogram_scipy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plasma=cm.get_cmap(name=\"plasma\", lut=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = figure(figsize=(8,16))\n",
    "ax = fig.add_subplot(111)\n",
    "linkage_tree = mi.cluster_dependent_features()\n",
    "\n",
    "drawer = DendrogramDrawer(\n",
    "    linkage_tree=linkage_tree,\n",
    "    style=DendrogramHeatmapStyle(ax=ax),\n",
    "    title='Feature clusters'\n",
    ")\n",
    "\n",
    "\n",
    "drawer.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkage_tree.n_leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = figure(figsize=(8,16))\n",
    "ax = fig.add_subplot(111)\n",
    "linkage_tree = mi.cluster_dependent_features()\n",
    "\n",
    "drawer = DendrogramDrawer(\n",
    "    linkage_tree=linkage_tree,\n",
    "    style=DendrogramLineStyle(ax=ax),\n",
    "    title='Feature clusters'\n",
    ")\n",
    "\n",
    "drawer.draw()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
